{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from transformers import pipeline\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - NER using rule-based parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lire un fichier docx et extraire son texte.\n",
    "def extract_text_from_docx(docx_path):\n",
    "    data  = Docx2txtLoader(docx_path).load()\n",
    "    return data[0].page_content.strip()\n",
    "\n",
    "#Génèrer les regex à des noms d'entités qu'on souhaite extraire\n",
    "def format_entity_patterns(entity_names):\n",
    "    return [rf\"{re.escape(name)}\\s*\\n(.+)\" for name in entity_names]\n",
    "\n",
    "\n",
    "#Appliquer les regex pour extraire des entités nommées\n",
    "def extract_entities(text,\n",
    "                      entities_names =  [\"Counterparty\", \"Initial Valuation Date\", \"Notional\", \"Valuation Date\", \"Maturity\", \"Underlying\", \"Coupon\", \"Barrier\", \"Calendar\"], \n",
    "                      entities_to_extract = [\"Party A\", \"Initial Valuation Date\", \"Notional Amount (N)\", \"Valuation Date\", \"Termination Date\",  \"Underlying\", \"Coupon (C)\", \"Barrier (B)\", \"Business Day\"]):\n",
    "    entities = {}\n",
    "    patterns = dict(zip(entities_names,  format_entity_patterns(entities_to_extract)))\n",
    "    for key, pattern in patterns.items():\n",
    "        match = re.search(pattern, text)\n",
    "        entities[key] = match.group(1) if match else None\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Counterparty': 'BANK ABC',\n",
       " 'Initial Valuation Date': '31 January 2025',\n",
       " 'Notional': 'EUR 1 million',\n",
       " 'Valuation Date': '31 January 2025',\n",
       " 'Maturity': '07 August 2026',\n",
       " 'Underlying': 'Allianz SE (ISIN DE0008404005, Reuters: ALVG.DE)',\n",
       " 'Coupon': '0%',\n",
       " 'Barrier': '75.00% of Shareini  ',\n",
       " 'Calendar': 'TARGET '}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx_text = extract_text_from_docx(\"data/ZF4894_ALV_07Aug2026_physical.docx\")\n",
    "extract_entities(docx_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - NER using open soure (hugging face) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()\n",
    "    \n",
    "def model_loader(model_path) :\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_path)\n",
    "    return pipeline(\"ner\", model=model, tokenizer=tokenizer,  aggregation_strategy=\"first\")\n",
    "\n",
    "\n",
    "def extract_named_entities_from_text(ner_pipeline, text) :\n",
    "    results = ner_pipeline(text)\n",
    "    entities = [{k: d[k] for k in [\"entity_group\", \"score\", \"word\"]} for d in results]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'ORG', 'score': 0.877728, 'word': 'BANK ABC'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./pretrained-models/distilbert-NER\"\n",
    "ner_pipeline = model_loader(model_path)\n",
    "\n",
    "text = read_text_file(\"data/FR001400QV82_AVMAFC_30Jun2028.txt\")\n",
    "extract_named_entities_from_text(ner_pipeline, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER for Verbose and complex PDF using RAG approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from src.llm_and_rag_ner import (extract_named_entities,\n",
    "                                retrieve_relevant_data,\n",
    "                                load_pdf,\n",
    "                                index_documents)\n",
    "\n",
    "model_path = \"pretrained-models/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_path,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexation\n",
    "index_path = \"./faiss-index\"\n",
    "chunks = load_pdf(\"./data/BankABC_TermSheet_Template.pdf\")\n",
    "index_documents(chunks, embedding_model, index_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 11 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting indexation in FAISS\n",
      "indexation terminated\n",
      "\n",
      "\n",
      "\n",
      "[Document(page_content='5 to a vote of shareholders of the Company. Subject to the Protective Provisions, the Preference Shares and the equity shares will have one vote per share determined on an as-converted basis. Protective Provisions: Consent of the Investor shall be required for any action that (i) alters or changes'), Document(page_content='the rights, preference or privileges of the Preference Shares, (ii) increases or decreases the authorized number of shares of equity or Preference Shares, (iii) creates any new class or series of shares having rights, preference or privileges senior to or on a parity with any outstanding series of'), Document(page_content='including all shares warrants and employee options for equity shares granted), with rights of subscription as to any unsubscribed shares. Voluntary Conversion: The Investor shall have the right to convert the Preference Shares at any time, at its option, into equity shares and shall be subject to'), Document(page_content='drag along right being enforced by any other investor. Proportionate ownership: The Investor shall have the right, in the event the Company proposes to offer equity securities to any person (other than')] \n",
      "\n",
      "\n",
      "5 to a vote of shareholders of the Company. Subject to the Protective Provisions, the Preference Shares and the equity shares will have one vote per share determined on an as-converted basis. Protective Provisions: Consent of the Investor shall be required for any action that (i) alters or changes\n",
      "the rights, preference or privileges of the Preference Shares, (ii) increases or decreases the authorized number of shares of equity or Preference Shares, (iii) creates any new class or series of shares having rights, preference or privileges senior to or on a parity with any outstanding series of\n",
      "including all shares warrants and employee options for equity shares granted), with rights of subscription as to any unsubscribed shares. Voluntary Conversion: The Investor shall have the right to convert the Preference Shares at any time, at its option, into equity shares and shall be subject to\n",
      "drag along right being enforced by any other investor. Proportionate ownership: The Investor shall have the right, in the event the Company proposes to offer equity securities to any person (other than\n",
      "\n",
      "\n",
      "\n",
      "NER performing\n",
      "NER finished\n",
      "{\n",
      "  \"ORG\": [\n",
      "    \"Investor\"\n",
      "  ],\n",
      "  \"INSTRUMENT\": [\n",
      "    \"Preference Shares\",\n",
      "    \"equity shares\",\n",
      "    \"warrants\",\n",
      "    \"employee options for equity shares\",\n",
      "    \"Convertible Preference Shares\"\n",
      "  ],\n",
      "  \"LEGAL_TERM\": [\n",
      "    \"Protective Provisions\",\n",
      "    \"drag along right\",\n",
      "    \"Voting Rights\",\n",
      "    \"Anti-dilution\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "######## Retrieving #########\n",
    "retriever = FAISS.load_local(index_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "query = \"\"\"Consent of the Investor shall be required for any action that \n",
    "          (i) alters or changes the rights, preference or privileges of the \n",
    "          Preference Shares, (ii) increases or decreases the authorized \n",
    "          number of shares of equity or Preference Shares\"\"\"\n",
    "aggragated_retrieved_text = retrieve_relevant_data(retriever, query)\n",
    "print(aggragated_retrieved_text)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "######## NER using  #########\n",
    "entities = extract_named_entities(aggragated_retrieved_text, 'mistral')\n",
    "print(json.dumps(entities, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER performing\n",
      "NER finished\n",
      "{\n",
      "  \"ORG\": [],\n",
      "  \"MONEY\": [\n",
      "    \"$10 million\"\n",
      "  ],\n",
      "  \"DATE\": [\n",
      "    \"Q1 2023\",\n",
      "    \"January 2025\"\n",
      "  ],\n",
      "  \"INSTRUMENT\": [\n",
      "    \"Convertible Preference Shares\"\n",
      "  ],\n",
      "  \"PERCENT\": [\n",
      "    \"25% IRR\"\n",
      "  ],\n",
      "  \"SHAREHOLDER\": [],\n",
      "  \"EXIT_STRATEGY\": [],\n",
      "  \"LEGAL_TERM\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "####### Test avec llama\n",
    "model='llama3.2'\n",
    "text = \"Elon Musk founded SpaceX in Los Angeles. Apple and Google are investing in France.\"\n",
    "entities = extract_named_entities(text, model)\n",
    "print(json.dumps(entities, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mollama\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ollama'"
     ]
    }
   ],
   "source": [
    "import ollama"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
